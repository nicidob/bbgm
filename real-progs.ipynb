{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import pdist, cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the historic player data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('real-player.json','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['ratings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['fuzz','abbrev_if_new_row'],1)#.set_index(['slug','season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(['slug','season']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings  = {}\n",
    "for row in df.itertuples():\n",
    "    ratings[(row[1],row[2])] = list(row[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bios']['abdulka01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings[('jordami01',1985)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use recent-ish players\n",
    "from collections import defaultdict\n",
    "player_year_rate = defaultdict(dict)\n",
    "for i,r in ratings.items():\n",
    "    if data['bios'][i[0]]['bornYear'] < 1956:\n",
    "        continue\n",
    "    if i[1] >= 2019:\n",
    "        continue\n",
    "    age=  i[1]-data['bios'][i[0]]['bornYear']\n",
    "    player_year_rate[i[0]][age] = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth their ratings\n",
    "plt.style.use('fivethirtyeight')\n",
    "import scipy\n",
    "SMOOTHING_STD = 1.0\n",
    "key = 'malonka01' # greendr01 jamesle01 hardeja01 malonka01\n",
    "play = player_year_rate[key] \n",
    "minY = min(play.keys())\n",
    "maxY = max(play.keys())\n",
    "res = []\n",
    "for i in range(minY,maxY+1):\n",
    "    #print(i)\n",
    "    #res.append(play.get(i,[np.nan for j in range(15)]))\n",
    "    res.append(play[i] if i in play else res[-1])\n",
    "\n",
    "i = 8\n",
    "plt.plot(range(minY,maxY+1),np.array(res)[:,i],label='orig')\n",
    "plt.plot(range(minY,maxY+1),scipy.ndimage.gaussian_filter1d(np.array(res).astype(float),SMOOTHING_STD,mode='nearest',axis=0,truncate=10)[:,i],label='smooth')\n",
    "plt.legend()\n",
    "plt.title(key + ' ' + cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_year_rateSmooth = {}\n",
    "for key,play in player_year_rate.items():\n",
    "    minY = min(play.keys())\n",
    "    maxY = max(play.keys())\n",
    "    res = []\n",
    "    for i in range(minY,maxY+1):\n",
    "        #res.append(play.get(i,[np.nan for j in range(15)]))\n",
    "        res.append(play[i] if i in play else res[-1])\n",
    "    res = np.array(res).astype(float)\n",
    "    reS = scipy.ndimage.gaussian_filter1d(res,SMOOTHING_STD,mode='nearest',axis=0,truncate=10)\n",
    "    p2 = {}\n",
    "    for idx,age in enumerate(range(minY,maxY+1)):\n",
    "        if age in play:\n",
    "            p2[age] = reS[idx]\n",
    "    play_year_rateSmooth[key] = p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANS_FUNC = lambda x: x**(1/2)#np.sqrt(x)\n",
    "INV_FUNC = lambda x: x**2#x**2\n",
    "r1 = []\n",
    "r2 = []\n",
    "for play in play_year_rateSmooth.values():\n",
    "    for age,r in play.items():\n",
    "        if age-1 in play:\n",
    "            age2 = age-1\n",
    "            if age2 > 36:\n",
    "                continue\n",
    "            r1.append(TRANS_FUNC(play[age]) -TRANS_FUNC(play[age-1]))\n",
    "            r2.append(age2)\n",
    "r1 = np.array(r1)\n",
    "r2 = np.array(r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_res = []\n",
    "for age in sorted(np.unique(r2)):\n",
    "    age_res.append(r1[r2==age].mean(0))\n",
    "age_res = np.array(age_res)\n",
    "for i in range(15):\n",
    "    plt.plot(sorted(np.unique(r2)),age_res[:,i],label=cols[i],c=plt.cm.tab20(i))\n",
    "plt.xlim(right=35)\n",
    "plt.legend()\n",
    "#plt.ylim(-0.2,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as linear_model\n",
    "from scipy.stats import pearsonr\n",
    "TIMES_TO_FIT = 1\n",
    "\n",
    "clf_models = []\n",
    "for i in range(TIMES_TO_FIT):\n",
    "    clf = linear_model.RidgeCV(np.logspace(-5,5,11),cv=5)#SGDRegressor('epsilon_insensitive',alpha=1e-5,epsilon=0,max_iter=10000,tol=1e-9,eta0=1e-5)\n",
    "    clf.fit(np.repeat(r2,15)[:,None],r1.ravel())\n",
    "    #score = clf.score(np.repeat(r2,15)[:,None],r1.ravel())\n",
    "    score = pearsonr(clf.predict(np.repeat(r2,15)[:,None]),r1.ravel())\n",
    "    clf_models.append((score,i,clf))\n",
    "best_model = sorted(clf_models)[0]\n",
    "clf = best_model[2]\n",
    "print(best_model[0])\n",
    "main_model = (clf.coef_[0] , clf.intercept_) # 0.0855008819536307 # 0.003181372399186653\n",
    "# (0.28535187287328784, 0.0) linear\n",
    "# (0.27993511134791604, 0.0) log/exp\n",
    "# (0.2882236878163602, 0.0) squared\n",
    "# (0.28735272142114926, 0.0) cubed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.unique(r2),np.unique(r2)*main_model[0] +main_model[1])\n",
    "plt.plot([19,35],[0,0],c='k',ls='--')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(r1.shape[1]):\n",
    "    clf_models = []\n",
    "    for j in range(TIMES_TO_FIT):\n",
    "        clf = linear_model.RidgeCV(np.logspace(-5,5,11),cv=5)#SGDRegressor('epsilon_insensitive',alpha=1e-5,epsilon=0,max_iter=10000,tol=1e-9,eta0=1e-5)\n",
    "        clf.fit(np.array(r2)[:,None],r1[:,i]-(main_model[0]*r2+main_model[1]))\n",
    "        score = clf.score(np.array(r2)[:,None],r1[:,i]-(main_model[0]*r2+main_model[1]))\n",
    "        clf_models.append((score,j,clf))\n",
    "    best_model = sorted(clf_models)[-1]\n",
    "    clf = best_model[2]\n",
    "    print(cols[i],best_model[0])\n",
    "    models.append((clf.coef_[0],clf.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "for i in range(r1.shape[1]):\n",
    "    plt.plot(np.unique(r2),np.unique(r2)*models[i][0]+models[i][1],label=cols[i],c=plt.cm.tab20(i))\n",
    "plt.legend()\n",
    "#plt.xlim(19,34)\n",
    "#plt.ylim(-4,4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_expected = []\n",
    "for i in range(r1.shape[1]):\n",
    "    means_expected.append((models[i][0]*r2 + models[i][1]) * (main_model[0]*r2+main_model[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank1 approximations of this would be really cool\n",
    "# but sampling multivariate Gaussians seems... annoying?\n",
    "removed_means = r1 - np.array(means_expected).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "i = 1\n",
    "for age in sorted(np.unique(r2)):\n",
    "    if (r2 == age).sum() < 2:\n",
    "          continue\n",
    "    plt.subplot(4,6,i)\n",
    "    i += 1\n",
    "    covar = np.cov(removed_means[r2 == age],rowvar=False)\n",
    "    plt.imshow(covar)\n",
    "    plt.xticks(np.arange(15),cols,rotation=45)\n",
    "    plt.yticks(np.arange(15),cols)\n",
    "    plt.title('age={}  max={:.1f}'.format(age,covar.max()))\n",
    "plt.tight_layout(pad=0.1,h_pad=0)\n",
    "plt.gcf().subplots_adjust(hspace=-0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_w = []\n",
    "ages = sorted(np.unique(r2))\n",
    "age_stds = []\n",
    "for age in ages:\n",
    "    age_w.append((r2==age).sum())\n",
    "    age_stds.append(removed_means[r2==age].std(axis=0))\n",
    "age_stds = np.array(age_stds)\n",
    "age_w = np.array(age_w)\n",
    "age_w = age_w/age_w.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeCV()#SGDRegressor(loss='epsilon_insensitive',alpha=0,epsilon=0)\n",
    "clf.fit(np.repeat(ages,15)[:,None],age_stds.ravel(),sample_weight=np.repeat(age_w,15))\n",
    "base_model = list(main_model) + [clf.coef_[0],clf.intercept_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.unique(r2),np.unique(r2)*clf.coef_[0] +clf.intercept_,lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_models = []\n",
    "for i in range(15):\n",
    "    clf = linear_model.RidgeCV()#SGDRegressor(loss='epsilon_insensitive',alpha=0,epsilon=0)\n",
    "    clf.fit(np.array(ages)[:,None],np.maximum(0,age_stds[:,i]-(np.array(ages)*base_model[2] + base_model[3])),sample_weight = age_w)\n",
    "    std_models.append((clf.coef_[0],clf.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "for i in range(r1.shape[1]):\n",
    "    plt.plot(np.unique(r2),np.unique(r2)*std_models[i][0] + std_models[i][1],label=cols[i],c=plt.cm.tab20(i),lw=3)\n",
    "plt.legend()\n",
    "plt.xlim(19,34)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_print = {cols[i]:tuple(np.round(row,4)) for i,row in enumerate(np.hstack([models,std_models]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{} {},'.format(\"base\",list(np.round(base_model,4))))\n",
    "for k,v in dat_print.items():\n",
    "    if k == 'hgt':continue\n",
    "    print('{}: {},'.format(k,list(v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(means_expected,0.99,axis=0).mean(),np.quantile(means_expected,0.01,axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(r1,0.99,axis=0).mean(),np.quantile(r1,0.01,axis=0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Rookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_weights =  {'diq': 0.093,\n",
    " 'dnk': 0.0424,\n",
    " 'drb': 0.0968,\n",
    " 'endu': 0.0075,\n",
    " 'fg': -0.0093,\n",
    " 'ft': 0.049,\n",
    " 'hgt': 0.225,\n",
    " 'ins': -0.0143,\n",
    " 'jmp': 0.0505,\n",
    " 'oiq': 0.0971,\n",
    " 'pss': 0.0657,\n",
    " 'reb': 0.0534,\n",
    " 'spd': 0.156,\n",
    " 'stre': 0.0962,\n",
    " 'tp': 0.105}\n",
    "ovr_v = np.array([ovr_weights[cols[i]] for i in range(len(cols))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_np = np.array(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youth = []\n",
    "names = []\n",
    "positions = []\n",
    "for k,p in data['bios'].items():\n",
    "    if 'bornYear' not in p or p['bornYear'] is None:\n",
    "        continue\n",
    "    yr = p['draftYear']\n",
    "    age = yr-p['bornYear']\n",
    "    if yr<2019 and yr >= 2000 and (k,yr+1) in ratings and age <= 23 and p['draftPick'] <= 45:\n",
    "        update = main_model[0]*age+main_model[1]\n",
    "        rt = ratings[(k,yr+1)]\n",
    "        rt_n = TRANS_FUNC(np.array(rt)+0.1) - ( (main_model[0]*age+main_model[1]) + (models_np[:,0]*age + models_np[:,1]) )\n",
    "        rt_n = np.clip(INV_FUNC(rt_n),1,100)\n",
    "        youth.append([age] + list(rt_n))\n",
    "        names.append(k)\n",
    "        positions.append(p['pos'])\n",
    "youth = np.array(youth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_play = np.array([v for k,v in ratings.items() if k[1] > 2000 and k[1] < 2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist((youth/youth.mean(0)).ravel(),50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "s1 = (youth[:,1:]*ovr_v).sum(1)\n",
    "s1 = s1 > 0*np.median(s1)\n",
    "\n",
    "clf_pca = PCA(whiten =False)#TSNE(perplexity=55)\n",
    "clf_pca.fit(youth[:,1:])\n",
    "emb = clf_pca.transform(youth[s1,1:].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = ['PG','G','SG',\"GF\",'SF','F','PF','FC',\"C\"]\n",
    "plt.scatter(emb[:,0],emb[:,1],c=[pos_set.index(_) for _,t in zip(positions,s1) if t],cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_mean = np.array([5., 0., 0., 5., 0., 0., 0., 0., 0., 5., 0., 0., 0., 0., 0.])\n",
    "for c,v in zip(cols,np.round(clf_pca.mean_,1)):\n",
    "    print(c,':',v,',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMP =3\n",
    "hgt = youth[:,1+cols.index('hgt')]\n",
    "plt.hist(hgt,25,density=True)\n",
    "rand_hgt = np.random.randn(1500)*13.6 + 47.5\n",
    "plt.hist(rand_hgt,25,alpha=0.5,density=True)\n",
    "f_hgt = np.array(list(hgt) + list(rand_hgt))\n",
    "\n",
    "X_hgt = hgt[s1,None]# np.vstack([hgt,hgt**2]).T\n",
    "pred_res = []\n",
    "hgt_models = []\n",
    "for i in range(COMP):\n",
    "    clf = linear_model.RidgeCV(cv=3,alphas=np.logspace(-5,3,9))\n",
    "    clf.fit(X_hgt,emb[:,i])\n",
    "    clf_s = clf.score( X_hgt,emb[:,i])\n",
    "    pred_res.append(clf.predict(f_hgt[:,None]))\n",
    "    print(clf_s)\n",
    "    hgt_models.append(list(clf.coef_) + [clf.intercept_])\n",
    "pred_res = np.array(pred_res).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "np.round(hgt_models,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(clf_pca.components_[:COMP,:],cmap='RdBu',vmin=-0.5,vmax=0.5)\n",
    "_ = plt.xticks(np.arange(15),cols,rotation=45)\n",
    "clf_pca.components_[:COMP,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = np.array([8.9, 19.9, 7.8])\n",
    "set2 = np.array([  -0.77, -11.06 ,  1.77])\n",
    "set3 = np.array([0.81, 0.41])\n",
    "ADD_VAR = set1*(np.random.randn(f_hgt.shape[0],COMP))+set2\n",
    "MUL_VAR = np.random.uniform(set3[0],set3[0]+set3[1],size=(f_hgt.shape[0],15))\n",
    "pred_vec = ((ADD_VAR+pred_res) @ clf_pca.components_[:COMP,:]) + clf_pca.mean_ \n",
    "pred_vec *= MUL_VAR\n",
    "pred_vec[:,cols.index('hgt')] = f_hgt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred_vec.ravel(),50,alpha=0.5,density=True)\n",
    "_= plt.hist(youth[:,1:].ravel(),50,alpha=0.5,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open('beta_sim_p.json','rb') as fp:\n",
    "        beta = json.load(fp)\n",
    "    pV = []\n",
    "    for p in beta['players']:\n",
    "        if p['ratings'][0]['season'] != p['draft']['year']:\n",
    "            continue\n",
    "        pV.append([p['ratings'][0][_] for _ in cols]) \n",
    "    pV = np.array(pV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist((youth[:,1:]*ovr_v).sum(1)-6.4,20,alpha=0.5,density=True,label='rpd')\n",
    "_ = plt.hist((pred_vec*ovr_v).sum(1)-6.4,20,alpha=0.5,density=True,label='gen')\n",
    "#_ = plt.hist((beta_p2*ovr_v).sum(1)-6.4,20,alpha=0.5,density=True,label='beta')\n",
    "\n",
    "plt.legend()\n",
    "print(youth[:,1:].mean(1).std(),pred_vec.mean(1).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(pV*ovr_v).sum(1).mean(),(pV*ovr_v).sum(1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred_vec*ovr_v).sum(1).mean(),(pred_vec*ovr_v).sum(1).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.cov(youth[:,1:],rowvar=False),vmin=-130,vmax=130,cmap='RdBu')\n",
    "plt.title('real players')\n",
    "plt.xticks(np.arange(15),cols,rotation=45)\n",
    "plt.yticks(np.arange(15),cols)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.cov(pred_vec,rowvar=False),vmin=-130,vmax=130,cmap='RdBu')\n",
    "plt.title('generated')\n",
    "plt.xticks(np.arange(15),cols,rotation=45)\n",
    "_ = plt.yticks(np.arange(15),cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC = 50\n",
    "s1 = (youth[:,1:]*ovr_v).sum(1)\n",
    "s1 = s1 > np.percentile(s1,PC)\n",
    "s2 = (pred_vec*ovr_v).sum(1)\n",
    "s2 = s2 > np.percentile(s2,PC)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(np.cov(youth[s1,1:],rowvar=False),vmin=-130,vmax=130,cmap='RdBu')\n",
    "plt.title('real players')\n",
    "plt.xticks(np.arange(15),cols,rotation=45)\n",
    "plt.yticks(np.arange(15),cols)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.cov(pred_vec[s2],rowvar=False),vmin=-130,vmax=130,cmap='RdBu')\n",
    "plt.title('generated')\n",
    "plt.xticks(np.arange(15),cols,rotation=45)\n",
    "_ = plt.yticks(np.arange(15),cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(abs(_).mean(),abs(_).max()) for _ in [youth[:,1:].mean(0)-pred_vec.mean(0),youth[s1,1:].mean(0)-pred_vec[s2].mean(0),youth[s1,1:].std(0)-pred_vec[s2].std(0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = (ovr_v*youth[s1,1:]).sum(1)\n",
    "v2 = (ovr_v*pred_vec[s2]).sum(1)\n",
    "tb = int(np.ceil(v1.max()))\n",
    "bb = int(np.floor(v1.min()))\n",
    "sN = tb-bb\n",
    "hist_set = np.linspace(bb,tb,sN)\n",
    "h1=np.histogram(v1,hist_set,density=True)[0]+1e-6\n",
    "h2 = np.histogram(v2,hist_set,density=True)[0]+1e-6\n",
    "((h1-h2)**2).sum()\n",
    "kl1 = (np.log(h1/h2)*h1).sum()\n",
    "kl2 = (np.log(h2/h1)*h2).sum()\n",
    "plt.hist(v1,alpha=0.5,density=True)\n",
    "plt.hist(v2,alpha=0.5,density=True)\n",
    "kl2+kl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_f(params):\n",
    "    #np.random.seed(43)\n",
    "    set1 = np.exp(params[:COMP])\n",
    "    set2 = np.array(params[-COMP:])\n",
    "    set3 = np.exp(params[COMP:COMP+2])\n",
    "    res = []\n",
    "    #print(set1,set2,set3)\n",
    "    for i in range(60):\n",
    "        np.random.seed(242+i)\n",
    "        ADD_VAR = set1*(np.random.randn(f_hgt.shape[0],COMP))+set2\n",
    "\n",
    "        MUL_VAR = np.random.uniform(set3[0],set3[0]+set3[1],size=(f_hgt.shape[0],15))\n",
    "        pred_vec = ((ADD_VAR+pred_res) @ clf_pca.components_[:COMP,:]) + clf_pca.mean_ \n",
    "        pred_vec *= MUL_VAR\n",
    "        pred_vec[:,cols.index('hgt')] = f_hgt\n",
    "        N = youth.shape[0]\n",
    "        # filter to only the top half with good stats\n",
    "        s1 = (youth[:,1:]*ovr_v).sum(1)\n",
    "        s1 = s1 > np.percentile(s1,PC)\n",
    "        s2 = (pred_vec*ovr_v).sum(1)\n",
    "        s2 = s2 > np.percentile(s2,PC)\n",
    "        \n",
    "        cov_err = ((np.cov(youth[s1,1:],rowvar=False)-np.cov(pred_vec[s2],rowvar=False))**2).mean()\n",
    "        cov_err2 = ((np.cov(youth[:,1:],rowvar=False)-np.cov(pred_vec,rowvar=False))**2).mean()\n",
    "\n",
    "        v1 = (ovr_v*youth[s1,1:]).sum(1)\n",
    "        v2 = (ovr_v*pred_vec[s2]).sum(1)\n",
    "        \n",
    "        tb = int(np.ceil(v1.max()))\n",
    "        bb = int(np.floor(v1.min()))\n",
    "        sN = tb-bb\n",
    "        hist_set1 = np.linspace(bb,tb,sN)\n",
    "\n",
    "        tb = int(np.ceil(v2.max()))\n",
    "        bb = int(np.floor(v2.min()))\n",
    "        sN = tb-bb\n",
    "        hist_set2 = np.linspace(bb,tb,sN)\n",
    "        \n",
    "        h1 = np.histogram(v1,hist_set1,density=True)[0]+1e-6\n",
    "        h2 = np.histogram(v2,hist_set1,density=True)[0]+1e-6\n",
    "        kl1 = (np.log(h1/h2)*h1).sum()\n",
    "        kl2 = (np.log(h2/h1)*h2).sum()\n",
    "        h1 = np.histogram(v1,hist_set2,density=True)[0]+1e-6\n",
    "        h2 = np.histogram(v2,hist_set2,density=True)[0]+1e-6\n",
    "        kl12 = (np.log(h1/h2)*h1).sum()\n",
    "        kl22 = (np.log(h2/h1)*h2).sum()\n",
    "        mean_err = kl1+kl2+kl12+kl22\n",
    "        \n",
    "        mean_err2 = ((youth[s1,1:].mean(0)-pred_vec[s2].mean(0))**2).sum()\n",
    "        mean_err3 = ((youth[:,1:].mean(0)-pred_vec.mean(0))**2).sum()\n",
    "        std_err1 = ((youth[s1,1:].std(0)-pred_vec[s2].std(0))**2).sum()\n",
    "        std_err2 = ((youth[:,1:].std(0)-pred_vec.std(0))**2).sum()\n",
    "\n",
    "        res.append( std_err1*(std_err2**0.1)*cov_err*mean_err*mean_err2*(mean_err3**0.1)*(cov_err2**0.1 )) # *mean_err3*cov_err2\n",
    "        if np.isnan(res[-1]):\n",
    "            return 1e20\n",
    "    return np.mean(sorted(res)) -10*set3[0]+10*set3[1] -np.sum(set1)+ np.linalg.norm(set2)\n",
    "\n",
    "x0 = np.array([  2.18455945,   2.99055438,   2.05511653,  -0.2050731 ,\n",
    "        -0.88629717,  -0.76933933, -11.05606385,   1.76523402])\n",
    "eval_f(x0)\n",
    "#plt.hist(eval_f(x0)[1],20,alpha=0.5,density=True)\n",
    "#plt.hist((ovr_v*youth[:,1:]).sum(1),20,density=True,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "es = cma.CMAEvolutionStrategy(x0,0.5,{'popsize':25.5})\n",
    "es.optimize(eval_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('beta_t.json','rb') as  fp:\n",
    "    rand_data = json.load(fp)\n",
    "beta_p2 = []\n",
    "for p in rand_data['players']:\n",
    "    if p['draft']['year'] != p['ratings'][0]['season']:\n",
    "        continue\n",
    "    #for rt1 in p['ratings']:\n",
    "    rt1 = p['ratings'][0]\n",
    "    beta_p2.append(np.array([rt1[_] for _ in cols]))\n",
    "beta_p2 = np.array(beta_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
