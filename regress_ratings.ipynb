{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('500_year.csv')#big_stat\n",
    "df = df.sample(frac = 1)\n",
    "#df = df[(df.G*df.MP > 850)]\n",
    "print(len(df.columns))\n",
    "#df.columns = dfc\n",
    "df.shape\n",
    "#df = df.sample(10000)\n",
    "player_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-15:]\n",
    "X = df.iloc[:,11:-17]\n",
    "\n",
    "X['MP'] = df.MP\n",
    "X['Hgt'] = df['Hgt']\n",
    "\n",
    "stat_list = ['FG','FGA','3P',\"3PA\",'FT','FTA',\\\n",
    "             'ORB','DRB','TRB','AST','TOV','STL',\"BLK\",\\\n",
    "             'PF','PTS']\n",
    "for name in stat_list:\n",
    "    den = np.maximum(1,df.MP)\n",
    "    X[name + 'p36'] = 36* df[name]/den\n",
    "    X[name + 'p100'] = X[name + 'p36']*4/3\n",
    "\n",
    "adv_stat_list = ['OWS','DWS','WS']\n",
    "for name in adv_stat_list:\n",
    "    \n",
    "    den = np.maximum(1,df.MP*df['G'])\n",
    "    #if name in ['OWS','DWS']:\n",
    "    #    den = den*df['G']\n",
    "    #X[name] = df[name]\n",
    "    X[name + 'p36_G72'] = 72*36* df[name]/den\n",
    "    \n",
    "\n",
    "X['3PtP'] = (2/(1+np.exp(-X['3PAp100']))-1)*X['3P%']/100\n",
    "X['Creation'] = X['ASTp100']*0.1843+(X['PTSp100']+X['TOVp100'])*0.0969-2.3021*X['3PtP']+0.0582*(X['ASTp100']*(X['PTSp100']+X['TOVp100'])*X['3PtP'] )-1.1942\n",
    "X['Load'] = (X['ASTp100']-(0.38*X['Creation'])*0.75)+X['FGAp100']+X['FTAp100']*0.44+X['Creation']+X['TOVp100']\n",
    "X['cTOV'] = X['TOVp100']/X['Load']\n",
    "#X['DPM'] = X['Blkp100']*0.802+X['DRBp100']*0.42-4.7-0.07551*X['PFp100']+1.597019*X['STLp100']-0.26385*X['TOVp100']\n",
    "#X['OPM'] = -8.57647+0.6111*X['PTSp100']-0.33918*(0.44*X['FTAp100']+X['FGAp100'])+0.440814*X['FTAp100']+0.379745*X['3PAp100']+0.634044*X['ASTp100']+0.77827*X['ORBp100']-1.08855*X['TOVp100']+0.26262*X['STLp100']\n",
    "#X['BPM'] = X['OPM'] + X['DPM']\n",
    "X['Age'] = df['Age']\n",
    "X['DRE'] = -8.4+ 0.8*X['PTSp100'] -0.7*(X['FGAp100']-X['3PAp100']) -0.6*X['3PAp100'] - 0.2*X['FTp100'] + 0.1*X['ORBp100'] + 0.4*X['DRBp100'] + 0.5*X['ASTp100'] + 1.7*X['STLp100'] + 0.8*X['BLKp100'] - 1.4*X['TOVp100'] - 0.1*X['PFp100']\n",
    "for name in [_ for _ in X.columns if 'FG' in _]:\n",
    "    name3 = name.replace('FG','3P')\n",
    "    if '%' in name or name3 not in list(X.columns):\n",
    "        continue\n",
    "    nname = name.replace('FG','2P')\n",
    "    X[nname] = X[name] - X[name3]\n",
    "\n",
    "banned_cols = ['eFG%','BA',\"DD\",\"TD\",'QD','5x5','EWA','FT/FGA','+/-'] \n",
    "banned_cols += ['AtRimFG', 'AtRimFGA', 'AtRimFGP', 'LowPostFG', 'LowPostFGA', 'LowPostFGP', 'MidRangeFG', 'MidRangeFGA', 'MidRangeFGP']\n",
    "banned_cols += [_ for _ in X.columns if 'p100' in _]\n",
    "banned_cols += ['2P','2PA']\n",
    "banned_cols += ['WS','OWS',\"DWS\",'VORP']\n",
    "\n",
    "banned_cols += stat_list\n",
    "\n",
    "# these seem to correlate poorly based on testing (see below)\n",
    "personal_list = ['DRtg','ORtg','3PAr','FT%','3PAp36','2P%','TS%','USG%','3PtP','FG%','3Pp36','3P%']\n",
    "banned_cols += personal_list\n",
    "X = X.drop(banned_cols,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if player_df:\n",
    "    plt.style.use('seaborn-white')\n",
    "    plt.style.use('default')\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(X.corr())\n",
    "    print(X.shape,player_df.shape)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(player_df.corr())\n",
    "    diffs = abs(X.corr() - player_df.corr()).mean(0)\n",
    "    print(diffs.sort_values(0,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_filter = (df.Salary > 0.5) & (df.Salary < 1.0)\n",
    "replacement_player_mean_bs = X[replacement_filter].mean()\n",
    "replacement_player_std_bs = X[replacement_filter].std()\n",
    "replacement_player_cov_bs = X[replacement_filter].cov()\n",
    "\n",
    "replacement_player_mean_r = y[replacement_filter].mean()\n",
    "replacement_player_std_r = y[replacement_filter].std()\n",
    "replacement_player_cov_r = y[replacement_filter].cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_weights =  {'diq': 0.093,\n",
    " 'dnk': 0.0424,\n",
    " 'drb': 0.0968,\n",
    " 'end': 0.0075,\n",
    " '2pt': -0.0093,\n",
    " 'ft.1': 0.049,\n",
    " 'hgt': 0.225,\n",
    " 'ins': -0.0143,\n",
    " 'jmp': 0.0505,\n",
    " 'oiq': 0.0971,\n",
    " 'pss': 0.0657,\n",
    " 'reb': 0.0534,\n",
    " 'spd': 0.156,\n",
    " 'str': 0.0962,\n",
    " '3pt': 0.105}\n",
    "\n",
    "ovr_weights = {\n",
    "    \"hgt\": 0.159,\n",
    "    \"str\": 0.777,\n",
    "    \"spd\":0.123,\n",
    "    \"jmp\":0.051,\n",
    "    \"end\": 0.0632,\n",
    "    \"ins\": 0.0126,\n",
    "    \"dnk\": 0.0286,\n",
    "    \"ft.1\": 0.0202,\n",
    "    \"3pt\": 0.0726,\n",
    "    \"oiq\": 0.133,\n",
    "    \"diq\": 0.159,\n",
    "    \"drb\": 0.059,\n",
    "    \"pss\": 0.062,\n",
    "    \"2pt\": 0.01,\n",
    "    \"reb\": 0.01,\n",
    "}\n",
    "ovr_weights = {k:v*0.7 for k,v in ovr_weights.items()} # because uhh yeah, the OG ovr is too big\n",
    "ovr_v = np.array([ovr_weights[c.lower()] for c in y.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection, model_selection\n",
    "from sklearn import  multioutput\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array([cc.alpha_ for cc in clf.estimators_]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexp = preprocessing.PolynomialFeatures(degree=1,interaction_only=False)\n",
    "scalerX = preprocessing.RobustScaler()\n",
    "scalery = preprocessing.StandardScaler()\n",
    "\n",
    "prescale_X = scalerX.fit_transform(fexp.fit_transform(X))\n",
    "prescale_y = scalery.fit_transform(y)\n",
    "wt = np.array(df.G*df.MP)[:,None]\n",
    "wt = wt/wt.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = int(round(0.15*len(prescale_X)))\n",
    "\n",
    "X_train2 = prescale_X[:-frac]\n",
    "y_train2 = prescale_y[:-frac]\n",
    "X_test2 = prescale_X[-frac:]\n",
    "y_test2 = prescale_y[-frac:]\n",
    "weight_train2 = wt[:-frac]\n",
    "weight_test2 =wt[-frac:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_opt(params):\n",
    "    l2_c = np.exp(params).mean()\n",
    "    A = X_train2.T @ (X_train2*weight_train2) + np.exp(l2_c)*np.identity(X_train2.shape[1])\n",
    "    Ainv = np.linalg.pinv(A)\n",
    "    coef = (Ainv @ X_train2.T) @ (y_train2*weight_train2)\n",
    "\n",
    "    pred_new = (((X_test2@coef - y_test2) * weight_test2)**2).mean()\n",
    "    print(pred_new)\n",
    "    return pred_new\n",
    "best_params = [-4]\n",
    "model_opt(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.optimize as opt\n",
    "#res = opt.minimize(model_opt,best_params,options={'disp':True,'maxiter':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res.x,np.exp(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = prescale_X.T @ (prescale_X*wt) + 20*np.identity(prescale_X.shape[1])\n",
    "Ainv = np.linalg.pinv(A)\n",
    "coef = (Ainv @ prescale_X.T) @ (prescale_y*wt)\n",
    "coef = coef.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#coef = pickle.load(open('simple_model1.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(coef,open('simple_model1.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns\n",
    "col_names = fexp.get_feature_names(X.columns)\n",
    "\n",
    "for i,c in enumerate(y.columns):\n",
    "    coeffs = coef[i] \n",
    "    v = np.argsort(abs(coeffs))[::-1]\n",
    "    print(c)\n",
    "    coeffs2 = [(coeffs[i2],col_names[i2]) for i2 in v[:80]]\n",
    "    #for v,n in sorted(coeffs2,reverse=True):\n",
    "    #    print('{:.2f} * {} + '.format(v,n),end='')\n",
    "    print('| Variable | Coeff |')\n",
    "    print('|----------|-------|')\n",
    "    for v,n in sorted(coeffs2,reverse=True):\n",
    "        print('|{:25s}|{:.2f}|'.format(n,v))\n",
    "    #for v,n in sorted(coeffs2,reverse=True):\n",
    "    #    print('\\t{:25s}\\t{:.2f}'.format(n,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = json.load(open('BBGM_ASG_2022_2022_preseason.json','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_YEAR = 2022\n",
    "adv = pd.read_csv('{}_adv.csv'.format(GEN_YEAR))\n",
    "poss = pd.read_csv('{}_poss.csv'.format(GEN_YEAR))\n",
    "\n",
    "adv['srID'] = adv.Player.map(lambda x: x.split('\\\\')[1])\n",
    "poss['srID'] = poss.Player.map(lambda x: x.split('\\\\')[1])\n",
    "\n",
    "multi = set(adv[adv.Tm == 'TOT'].srID)\n",
    "\n",
    "adv1 = adv[adv.srID.map(lambda x: x in multi) & (adv.Tm == 'TOT') ]\n",
    "adv2 = adv[~adv.srID.map(lambda x: x in multi)]\n",
    "adv = pd.concat([adv1,adv2]).set_index('srID')\n",
    "\n",
    "multi = set(poss[poss.Tm == 'TOT'].srID)\n",
    "poss1 = poss[poss.srID.map(lambda x: x in multi) & (poss.Tm == 'TOT') ]\n",
    "poss2 = poss[~poss.srID.map(lambda x: x in multi)]\n",
    "poss = pd.concat([poss1,poss2]).set_index('srID')\n",
    "\n",
    "df_nba = pd.merge(poss.dropna(1,how='all'),adv.dropna(1,how='all'),how=\"inner\", left_index=True, right_index=True)\n",
    "#df_nba = df_nba.dropna(1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = {}\n",
    "for p in base['players']:\n",
    "    if 'srID' not in p:\n",
    "        continue\n",
    "    heights[p['srID']] = p['hgt']\n",
    "df_nba['height'] = pd.Series(heights)\n",
    "df_nba = df_nba.dropna()\n",
    "df_nba.columns = [_.replace('%','p') for _ in df_nba.columns]\n",
    "df_nba['height'] = np.clip((df_nba.height-66)*3.70,0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE_SCALES = ['FG%','TS%','3P%','FT%','3PAr','2P%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_vectors = []\n",
    "player_scales = []\n",
    "player_heights = []\n",
    "player_names = []\n",
    "for idx,row in df_nba.iterrows():\n",
    "    d = dict(row)\n",
    "    \n",
    "    d['Hgt'] = row['height']\n",
    "    d['Age']= row['Age_x']\n",
    "\n",
    "    d['DRE'] = -8.4+ 0.8*d['PTS'] -0.7*(d['FGA']-d['3PA']) -0.6*d['3PA'] - 0.2*d['FT'] + 0.1*d['ORB'] + 0.4*d['DRB'] + 0.5*d['AST'] + 1.7*d['STL'] + 0.8*d['BLK'] - 1.4*d['TOV'] - 0.1*d['PF']\n",
    "    d['3PtP'] = (2/(1+np.exp(-d['3PA']))-1)*d['3Pp']\n",
    "    d['Creation'] = d['AST']*0.1843+(d['PTS']+d['TOV'])*0.0969-2.3021*d['3PtP']+0.0582*(d['AST']*(d['PTS']+d['TOV'])*d['3PtP'] )-1.1942\n",
    "    d['Load'] = (d['AST']-(0.38*d['Creation'])*0.75)+d['FGA']+d['FTA']*0.44+d['Creation']+d['TOV']\n",
    "    d['cTOV'] = d['TOV']/d['Load']\n",
    "    #d['DPM'] = d['BLK']*0.802+d['DRB']*0.42-4.7-0.07551*d['PF']+1.597019*d['STL']-0.26385*d['TOV']\n",
    "    #d['OPM'] = -8.57647+0.6111*d['PTS']-0.33918*(0.44*d['FTA']+d['FGA'])+0.440814*d['FTA']+0.379745*d['3PA']+0.634044*d['AST']+0.77827*d['ORB']-1.08855*d['TOV']+0.26262*d['STL']\n",
    "    #d['BPM'] = d['OPM']+d['DPM']\n",
    "\n",
    "    MPo = np.maximum(1,np.nan_to_num(d['MP_x']))\n",
    "    MP = MPo\n",
    "    for statn in adv_stat_list:\n",
    "        d[statn+'p36_G72'] = 72*36*float(d[statn])/MPo#72*36*d[statn]/MPo\n",
    "    for s in RATE_SCALES:\n",
    "        d[s.replace('%','p')] *= 100\n",
    "    \n",
    "    d['MP'] = row['MP_x']/row['G_x']\n",
    "    d['Blk'] = d['BLK']\n",
    "\n",
    "    player_vectors.append([d[stat.replace('p36','').replace('%','p') if 'G72' not in stat else stat] for stat in X.columns])\n",
    "    player_scales.append(MP)\n",
    "    player_heights.append(d['Hgt'])\n",
    "    player_names.append(idx)\n",
    "player_df = pd.DataFrame(player_vectors,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = np.nan_to_num(np.array(player_vectors))\n",
    "Xn = np.nan_to_num(Xn)\n",
    "first_n = Xn.shape[0]\n",
    "#Xn.shape,Xn_s.shape,prescale_X.shape,fexp.n_input_features_,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array(player_scales)\n",
    "print(c.max())\n",
    "scaling = (c.max()/3028) * 256 # adjust for era\n",
    "c = np.array(player_scales).reshape((-1,1))\n",
    "c = np.tanh(c/scaling) # basically 1 by 512 MP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,250),np.tanh(np.linspace(0,250) * (256/3028)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-100]  + list(range(20,100,3)) + [200]\n",
    "base_hist = np.histogram((y*ovr_v).sum(1),bins,density=True)[0] + 1e-9\n",
    "base_hist2 = np.histogram(np.array(y).ravel(),bins,density=True)[0] + 1e-9\n",
    "\n",
    "\n",
    "def just_a_thing(qrange):\n",
    "    #Xn = np.nan_to_num(np.array(player_vectors))\n",
    "    # tuned this to get roughly 8-12 players at 70 or above. Which seemed like normal for a league\n",
    "    scalerX2 = preprocessing.RobustScaler(quantile_range=tuple(sorted(np.clip(qrange,1,99))))\n",
    "\n",
    "    #scalerX2 = scalerX\n",
    "    Xn_s = fexp.transform(np.nan_to_num(Xn))\n",
    "    Xsub = Xn_s[:first_n]\n",
    "    Xsub = Xsub[(c.ravel()[:first_n] > 0.15)]\n",
    "\n",
    "    scalerX2.fit(Xsub)\n",
    "    Xn_fs =scalerX2.transform(Xn_s)\n",
    "\n",
    "    predict = Xn_fs @ coef.T\n",
    "    predict = (predict - predict.mean(0))/predict.std(0)\n",
    "    ratings = np.nan_to_num(scalery.inverse_transform(predict))\n",
    "    #ratings[:,0] = Xn[:,list(X.columns).index('Hgt')]\n",
    "    HGT_PRED = 0.35\n",
    "    #if 'Hgt' in list(X.columns):\n",
    "    #ratings[:,0] = HGT_PRED*ratings[:,0] + (1-HGT_PRED)* np.array(player_heights)\n",
    "    ratings[:,0] = HGT_PRED*np.array(player_heights) + (1-HGT_PRED)*np.maximum(ratings[:,0],np.array(player_heights))\n",
    "    # now we can sample directly from ratings\n",
    "\n",
    "    # if we want to scale players down based on minutes played to replacement level\n",
    "    if True:\n",
    "        ratings[:predict.shape[0]] = ratings[:predict.shape[0]]*c + (1-c)*np.repeat(np.array(replacement_player_mean_r).reshape((-1,1)),predict.shape[0],1).T\n",
    "    \n",
    "    est_hist = np.histogram((ratings*ovr_v).sum(1),bins,density=True)[0] + 1e-6\n",
    "    \n",
    "    kl1 = est_hist * np.log(est_hist/base_hist)\n",
    "    kl2 = base_hist * np.log(base_hist/est_hist)\n",
    "    \n",
    "    est_hist2 = np.histogram(ratings.ravel(),bins,density=True)[0] + 1e-6\n",
    "    \n",
    "    kl3 = est_hist2 * np.log(est_hist2/base_hist2)\n",
    "    kl4 = base_hist2 * np.log(base_hist2/est_hist2)\n",
    "    \n",
    "    covar_err = abs((np.cov(ratings.T)-np.cov(y.T)).ravel()).sum()**0.5\n",
    "    mean_err = abs(ratings.mean(0)-y.mean(0)).sum()**0.5\n",
    "    ovr_err = (kl1.sum()+kl2.sum())**0.2\n",
    "    #print(ovr_err,covar_err,mean_err)\n",
    "    return ovr_err*covar_err*mean_err  #+ kl3.sum()  + kl4.sum()\n",
    "qrange_init =[2,72] # don't ask me why. seems to work fine and where it typically converges\n",
    "just_a_thing(qrange_init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "es = cma.CMAEvolutionStrategy(qrange_init,1,{'popsize':10,'maxfevals':200})\n",
    "es.optimize(just_a_thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrange = sorted(np.clip(es.best.x,1,99))\n",
    "qrange,es.best.f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xn = np.nan_to_num(np.array(player_vectors))\n",
    "# tuned this to get roughly 8-12 players at 70 or above. Which seemed like normal for a league\n",
    "scalerX2 = preprocessing.RobustScaler(quantile_range=tuple(qrange))\n",
    "\n",
    "#scalerX2 = scalerX\n",
    "Xn_s = fexp.transform(np.nan_to_num(Xn))\n",
    "Xsub = Xn_s[:first_n]\n",
    "Xsub = Xsub[(c.ravel()[:first_n] > 0.15)]\n",
    "\n",
    "scalerX2.fit(Xsub)\n",
    "Xn_fs =scalerX2.transform(Xn_s)\n",
    "\n",
    "predict =  Xn_fs @ coef.T\n",
    "predict = (predict - predict.mean(0))/predict.std(0)\n",
    "ratings = np.nan_to_num(scalery.inverse_transform(predict))\n",
    "#ratings[:,0] = Xn[:,list(X.columns).index('Hgt')]\n",
    "HGT_PRED = 0.35\n",
    "#if 'Hgt' in list(X.columns):\n",
    "#ratings[:,0] = HGT_PRED*ratings[:,0] + (1-HGT_PRED)* np.array(player_heights)\n",
    "ratings[:,0] = HGT_PRED*np.array(player_heights) + (1-HGT_PRED)*np.maximum(ratings[:,0],np.array(player_heights))\n",
    "# now we can sample directly from ratings\n",
    "\n",
    "# if we want to scale players down based on minutes played to replacement level\n",
    "if True:\n",
    "    ratings[:predict.shape[0]] = ratings[:predict.shape[0]]*c + (1-c)*np.repeat(np.array(replacement_player_mean_r).reshape((-1,1)),predict.shape[0],1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.cov(ratings.T))\n",
    "plt.figure()\n",
    "plt.imshow(np.cov(y.T))\n",
    "abs(ratings.mean(0)-y.mean(0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((ratings*ovr_v).sum(1),bins,alpha=0.5,density=True,label='NBA')\n",
    "plt.hist((y*ovr_v).sum(1),bins,alpha=0.5,density=True,label='BBGM')\n",
    "plt.xlim(20,100)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGT_PRED = 0.5\n",
    "player_heights = np.array(player_heights)\n",
    "\n",
    "def normalize(fro,to):\n",
    "    tm,ts = to.mean(),to.std()\n",
    "    fm,fs = fro.mean(),fro.std()\n",
    "    z = (fro-fm)/fs\n",
    "    return z*ts + tm\n",
    "nr = normalize(ratings[:,0],player_heights)\n",
    "tmp = np.clip(HGT_PRED*np.array(player_heights) + (1-HGT_PRED)*np.maximum(nr,player_heights),0,100)\n",
    "\n",
    "if False:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    _ = plt.hist(player_heights,15,alpha=0.8,density=True,label='NBA')\n",
    "    _ = plt.hist(np.clip(ratings[:,0],0,100),15,alpha=0.5,density=True,label='Model')\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,0.05)\n",
    "    plt.legend()\n",
    "    plt.subplot(1,3,2)\n",
    "    _ = plt.hist(player_heights,15,alpha=0.8,density=True,label='NBA')\n",
    "    plt.hist(tmp,15,alpha=0.5,density=True,label='Blended',color='#2ca02c')\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,0.05)\n",
    "    plt.legend()\n",
    "    plt.subplot(1,3,3)\n",
    "    _ = plt.hist(df['Hgt'],15,alpha=0.8,density=True,label='BBGM',color='#7f7f7f')\n",
    "    plt.hist(tmp,15,alpha=0.5,density=True,label='Blended',color='#2ca02c')\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,0.05)\n",
    "    plt.legend()\n",
    "    plt.savefig('test.png',edgecolor='w',facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(player_heights,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ratings[:,0]\n",
    "#table_columns['per_minute']#,table_columns['advanced'].index('0-3')\n",
    "#for i,t in enumerate(player_stats[name]['advanced'][0]):\n",
    "#    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_vectors[player_names.index('Joel Embiid')][list(X.columns).index('OWSp36')],X.columns[list(X.columns).index('OWSp36')]\n",
    "#player_stats[2019]['Joel Embiid']['advanced'][0][12],player_stats[2019]['Joel Embiid']['per_game'][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plt.hist(Xn[:,list(X.columns).index('FTp36')],150,density=True,alpha=0.5,label='NBA')\n",
    "#_ = plt.hist(X['FTp36'],150,alpha=0.5,density=True,label='BBGM')\n",
    "#plt.legend()\n",
    "#plt.figure()\n",
    "_ = plt.hist(player_heights,15,density=True,alpha=0.5,label='NBA')\n",
    "_ = plt.hist(ratings[:,0],15,alpha=0.5,density=True,label='BBGM')\n",
    "plt.title('height distribution')\n",
    "plt.legend()\n",
    "plt.xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean(0)-Xn.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def load_roster(filename):\n",
    "    base = json.load(open(filename,'rb'))\n",
    "    players = base['players']\n",
    "    return players,base\n",
    "playersOG,base = load_roster('BBGM_ASG_2022_2022_preseason.json')\n",
    "abbrev_to_tid = {_['abbrev']:_['tid'] for _ in base['teams']}\n",
    "abbrev_to_tid['BRK'] = abbrev_to_tid['BKN']\n",
    "abbrev_to_tid['CHO'] = abbrev_to_tid['CHA']\n",
    "abbrev_to_tid['GSW'] = abbrev_to_tid['GS']\n",
    "abbrev_to_tid['NOP'] = abbrev_to_tid['NOL']\n",
    "abbrev_to_tid['NYK'] = abbrev_to_tid['NYC']\n",
    "abbrev_to_tid['SAS'] = abbrev_to_tid['SA']\n",
    "\n",
    "\n",
    "y_keys = [_.lower() for _ in y.columns]\n",
    "\n",
    "y_map = { 'hgt': 'hgt',\n",
    "   'stre': 'str',\n",
    "   'spd': 'spd',\n",
    "   'jmp': 'jmp',\n",
    "   'endu': 'end',\n",
    "   'ins': 'ins',\n",
    "   'dnk': 'dnk',\n",
    "   'ft': 'ft.1',\n",
    "   'fg': '2pt',\n",
    "   'tp': '3pt',\n",
    "   'diq': 'diq',\n",
    "   'oiq': 'oiq',\n",
    "   'drb': 'drb',\n",
    "   'pss': 'pss',\n",
    "   'reb': 'reb' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_ for _ in base['players'] if 'srID' in _ and _['srID'] == 'doncilu01']\n",
    "#base['players'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_lookup = {}\n",
    "r_min = {}\n",
    "for name,r,mp in zip(player_names,ratings,np.squeeze(c)):\n",
    "    r_vec = {k: r[y_keys.index(km)] for k,km in y_map.items()}\n",
    "    r_vec = {k: int(np.clip(v,0,100)) for k,v in r_vec.items()}\n",
    "    r_vec['season'] = GEN_YEAR\n",
    "    r_lookup[name] = r_vec\n",
    "    r_min[name] = mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_cols =['value','valueNoPot','valueFuzz','valueNoPotFuzz','fuzz']\n",
    "for i in range(len(base['players'])):\n",
    "    if 'srID' not in base['players'][i]:\n",
    "        #print(base['players'][i]['firstName'] + ' ' + base['players'][i]['lastName'])\n",
    "        continue\n",
    "    srID = base['players'][i]['srID']\n",
    "    if srID not in r_lookup:\n",
    "        print(base['players'][i]['firstName'] + ' ' + base['players'][i]['lastName'],srID)\n",
    "        continue\n",
    "    if r_min[srID] < 0.8:\n",
    "        continue\n",
    "    base['players'][i]['ratings'][-1] = r_lookup[srID]\n",
    "    for idx in range(len(base['players'][i]['ratings'])):\n",
    "        for thing in filt_cols:\n",
    "            rt = base['players'][i]['ratings'][idx]\n",
    "            if thing in rt:\n",
    "                del base['players'][i]['ratings'][idx][thing]\n",
    "    for thing in filt_cols:\n",
    "        if thing in base['players'][i]:\n",
    "            del base['players'][i][thing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auto_roster_{}.json'.format(GEN_YEAR),'wt') as fp:\n",
    "    json.dump(base,fp, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
