{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('500_year.csv')#big_stat\n",
    "#df = df[(df.G*df.MP > 850)]\n",
    "print(len(df.columns))\n",
    "#df.columns = dfc\n",
    "df.shape\n",
    "#df = df.sample(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-15:]\n",
    "X = df.iloc[:,11:-17]\n",
    "#y = y[(X['AST%'] >0) & (X['AST%'] < 100)]\n",
    "print(X.shape)\n",
    "#X = X[(X['AST%'] >0) & (X['AST%'] < 100)]\n",
    "print(X.shape)\n",
    "\n",
    "X['MP'] = df.MP\n",
    "X['Hgt'] = df['Hgt']\n",
    "\n",
    "stat_list = ['FG','FGA','3P',\"3PA\",'FT','FTA',\\\n",
    "             'ORB','DRB','TRB','AST','TOV','STL',\"BLK\",\\\n",
    "             'PF','PTS']\n",
    "for name in stat_list:\n",
    "    den = np.maximum(1,df.MP)\n",
    "    X[name + 'p36'] = 36* df[name]/den\n",
    "    X[name + 'p100'] = X[name + 'p36']*4/3\n",
    "\n",
    "adv_stat_list = ['OWS','DWS','WS']\n",
    "for name in adv_stat_list:\n",
    "    \n",
    "    den = np.maximum(1,df.MP*df['G'])\n",
    "    #if name in ['OWS','DWS']:\n",
    "    #    den = den*df['G']\n",
    "    #X[name] = df[name]\n",
    "    X[name + 'p36_G72'] = 72*36* df[name]/den\n",
    "    \n",
    "\n",
    "X['3PtP'] = (2/(1+np.exp(-X['3PAp100']))-1)*X['3P%']/100\n",
    "X['Creation'] = X['ASTp100']*0.1843+(X['PTSp100']+X['TOVp100'])*0.0969-2.3021*X['3PtP']+0.0582*(X['ASTp100']*(X['PTSp100']+X['TOVp100'])*X['3PtP'] )-1.1942\n",
    "X['Load'] = (X['ASTp100']-(0.38*X['Creation'])*0.75)+X['FGAp100']+X['FTAp100']*0.44+X['Creation']+X['TOVp100']\n",
    "X['cTOV'] = X['TOVp100']/X['Load']\n",
    "#X['DPM'] = X['Blkp100']*0.802+X['DRBp100']*0.42-4.7-0.07551*X['PFp100']+1.597019*X['STLp100']-0.26385*X['TOVp100']\n",
    "#X['OPM'] = -8.57647+0.6111*X['PTSp100']-0.33918*(0.44*X['FTAp100']+X['FGAp100'])+0.440814*X['FTAp100']+0.379745*X['3PAp100']+0.634044*X['ASTp100']+0.77827*X['ORBp100']-1.08855*X['TOVp100']+0.26262*X['STLp100']\n",
    "#X['BPM'] = X['OPM'] + X['DPM']\n",
    "X['Age'] = df['Age']\n",
    "X['DRE'] = -8.4+ 0.8*X['PTSp100'] -0.7*(X['FGAp100']-X['3PAp100']) -0.6*X['3PAp100'] - 0.2*X['FTp100'] + 0.1*X['ORBp100'] + 0.4*X['DRBp100'] + 0.5*X['ASTp100'] + 1.7*X['STLp100'] + 0.8*X['BLKp100'] - 1.4*X['TOVp100'] - 0.1*X['PFp100']\n",
    "for name in [_ for _ in X.columns if 'FG' in _]:\n",
    "    name3 = name.replace('FG','3P')\n",
    "    if '%' in name or name3 not in list(X.columns):\n",
    "        continue\n",
    "    nname = name.replace('FG','2P')\n",
    "    X[nname] = X[name] - X[name3]\n",
    "    print(name)\n",
    "\n",
    "#else:\n",
    "#X['PER'] = df['PER']\n",
    "\n",
    "    #X['DREO'] = X['PTSp100'] + .2*X['TRBp100'] + .5*X['ASTp100'] - .9*X['FGAp100'] - .35*X['FTAp100']-6.23\n",
    "#X['PassP'] = ((X['ASTp100']-(0.38*X['Creation']))*0.752+ X['Creation'] + X['TOVp100']) ** 0.67\n",
    "#'OPM','DPM','cTOV','Load'#stat_list[:-2]+\n",
    "#'PER','FG%','DREO'\n",
    "\n",
    "\n",
    "\n",
    "X = X[[_ for _ in X.columns if '%' in _ or _[-1]=='r' or 'p36' in _ or _ in (['MP','TS%','FT%','3P%','OSPM','PER','DRE','FT%','OPM','BPM','DPM','Creation','cTOV','Load','Age','MP'])]]\n",
    "if False:\n",
    "    X = X[[_ for _ in X.columns if not '3P' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Rim' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Post' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Mid' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'TOV' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'Blk' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'ORB' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'DRB' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'STL' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'DPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'OPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'BPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not '+/-' in _]]\n",
    "else:\n",
    "    X = X[[_ for _ in X.columns if not 'FG%' in _]]\n",
    "    X = X[[_ for _ in X.columns if not '2P%' in _]]\n",
    "    X = X[[_ for _ in X.columns if _ not in ['2Pp36','2PAp36','3PAr']]]\n",
    "    X = X[[_ for _ in X.columns if not 'BPM' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'TRB' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'DRB%' in _]]\n",
    "    X = X[[_ for _ in X.columns if not 'ORB%' in _]]\n",
    "    X = X[[_ for _ in X.columns if _ not in ['AST%','STL%','BLK%','TOV%','USG%','TS%']]]\n",
    "\n",
    "#X['OBPM'] = df['OBPM']\n",
    "#X['DBPM'] = df['DBPM']\n",
    "#X = X[[_ for _ in X.columns if not '3PAr' in _]]\n",
    "\n",
    "replacement_filter = (df.Salary > 0.5) & (df.Salary < 1.0)\n",
    "replacement_player_mean_bs = X[replacement_filter].mean()\n",
    "replacement_player_std_bs = X[replacement_filter].std()\n",
    "replacement_player_cov_bs = X[replacement_filter].cov()\n",
    "\n",
    "replacement_player_mean_r = y[replacement_filter].mean()\n",
    "replacement_player_std_r = y[replacement_filter].std()\n",
    "replacement_player_cov_r = y[replacement_filter].cov()\n",
    "\n",
    "\n",
    "replacement_player_mean_r\n",
    "\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_weights =  {'diq': 0.093,\n",
    " 'dnk': 0.0424,\n",
    " 'drb': 0.0968,\n",
    " 'end': 0.0075,\n",
    " '2pt': -0.0093,\n",
    " 'ft.1': 0.049,\n",
    " 'hgt': 0.225,\n",
    " 'ins': -0.0143,\n",
    " 'jmp': 0.0505,\n",
    " 'oiq': 0.0971,\n",
    " 'pss': 0.0657,\n",
    " 'reb': 0.0534,\n",
    " 'spd': 0.156,\n",
    " 'str': 0.0962,\n",
    " '3pt': 0.105}\n",
    "ovr_v = np.array([ovr_weights[c.lower()] for c in y.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.round(replacement_player_std_r).astype(np.int)\n",
    "#_ =  plt.hist(X['OSPM'],150)\n",
    "#X['OSPM'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neural_network\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection, model_selection\n",
    "from sklearn import  multioutput\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array([cc.alpha_ for cc in clf.estimators_]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fexp = preprocessing.PolynomialFeatures(degree=2,interaction_only=False)\n",
    "scalerX = preprocessing.RobustScaler()\n",
    "scalery = preprocessing.StandardScaler()\n",
    "\n",
    "prescale_X = fexp.fit_transform(X)\n",
    "prescale_X = scalerX.fit_transform(prescale_X)\n",
    "\n",
    "prescale_y = scalery.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(prescale_X, prescale_y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas2 = [\n",
    " 0.0012093412968659217,\n",
    " 0.0021644471822303744,\n",
    " 0.002476479841448311,\n",
    " 0.003984192886046182,\n",
    " 0.0033815611873227974,\n",
    " 0.0059244781808397125,\n",
    " 0.006696280944494202]\n",
    "alphas2 = np.linspace(0.001,0.007,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_max = (np.sqrt(np.sum(prescale_X ** 2, axis=1)).max() /\n",
    "             (prescale_X.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_max = 1.0\n",
    "eps = 1e-6\n",
    "n_alphas = 10\n",
    "alphas = np.logspace(np.log10(alpha_max * eps), np.log10(alpha_max),\n",
    "                       num=n_alphas)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prescale_X = np.append(prescale_X,np.zeros_like(prescale_X[:,0:1]),1)\n",
    "X_train2, X_test2, y_train2, y_test2 = model_selection.train_test_split(prescale_X, prescale_y, test_size=0.15, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2.shape[0],y_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = prescale_X.T @ prescale_X + np.exp(-8)*np.identity(prescale_X.shape[1])\n",
    "Ainv = np.linalg.pinv(A)\n",
    "coef = (Ainv @ prescale_X.T) @ prescale_y\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 1\n",
    "ts = []\n",
    "for i in range(trials):\n",
    "    #clf = neural_network.MLPRegressor((36,5,24,36),'tanh',solver='adam',max_iter=1000)\n",
    "    #clf = neural_network.MLPRegressor((),'identity',solver='lbfgs',alpha=5e2,tol=1e-9)\n",
    "    #clf = multioutput.MultiOutputRegressor(linear_model.SGDRegressor(penalty='l2',verbose=True))\n",
    "    #clf = multioutput.MultiOutputRegressor(linear_model.ElasticNetCV(cv=3,n_alphas=10,max_iter=2500))\n",
    "    #clf = multioutput.MultiOutputRegressor(linear_model.RidgeCV(cv=3))\n",
    "    clf = multioutput.MultiOutputRegressor(linear_model.ElasticNet(alpha=0.001, max_iter=5000))\n",
    "\n",
    "    #clf = multioutput.MultiOutputRegressor(linear_model.ElasticNet(alpha=5e-3,l1_ratio=0.5))\n",
    "\n",
    "    #clf = ensemble.ExtraTreesRegressor(8,criterion='mae',max_depth=3,verbose=1)\n",
    "    #clf = multioutput.MultiOutputRegressor(svm.SVR())\n",
    "    #clf.fit(X_train,y_train)\n",
    "    #print(clf.score(X_train,y_train),clf.score(X_test,y_test))\n",
    "    clf.fit(prescale_X,prescale_y,np.array(df.G*df.MP))\n",
    "    yt = scalery.inverse_transform(clf.predict(prescale_X))\n",
    "    err = np.linalg.norm(yt-y)\n",
    "    ts.append((err,clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#clf = pickle.load(open('model_dump.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf,open('model_dump_weighted_play.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = sorted(ts)[::1] # why not the biggest error\n",
    "print(ts[0][0])\n",
    "clf = ts[0][1] # 7179 for RidgeCV # 7321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = X.columns\n",
    "col_names = fexp.get_feature_names(X.columns)\n",
    "\n",
    "for i,c in enumerate(y.columns):\n",
    "    coeffs = clf.estimators_[i].coef_ \n",
    "    v = np.argsort(abs(coeffs))[::-1]\n",
    "    print(c)\n",
    "    coeffs2 = [(coeffs[i2],col_names[i2]) for i2 in v[:80]]\n",
    "    #for v,n in sorted(coeffs2,reverse=True):\n",
    "    #    print('{:.2f} * {} + '.format(v,n),end='')\n",
    "    print('| Variable | Coeff |')\n",
    "    print('|----------|-------|')\n",
    "    for v,n in sorted(coeffs2,reverse=True):\n",
    "        print('|{:25s}|{:.2f}|'.format(n,v))\n",
    "    #for v,n in sorted(coeffs2,reverse=True):\n",
    "    #    print('\\t{:25s}\\t{:.2f}'.format(n,v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = json.load(open('BBGM_ASG_2022_2022_preseason.json','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEN_YEAR = 2022\n",
    "adv = pd.read_csv('{}_adv.csv'.format(GEN_YEAR))\n",
    "poss = pd.read_csv('{}_poss.csv'.format(GEN_YEAR))\n",
    "\n",
    "adv['srID'] = adv.Player.map(lambda x: x.split('\\\\')[1])\n",
    "poss['srID'] = poss.Player.map(lambda x: x.split('\\\\')[1])\n",
    "\n",
    "multi = set(adv[adv.Tm == 'TOT'].srID)\n",
    "\n",
    "adv1 = adv[adv.srID.map(lambda x: x in multi) & (adv.Tm == 'TOT') ]\n",
    "adv2 = adv[~adv.srID.map(lambda x: x in multi)]\n",
    "adv = pd.concat([adv1,adv2]).set_index('srID')\n",
    "\n",
    "multi = set(poss[poss.Tm == 'TOT'].srID)\n",
    "poss1 = poss[poss.srID.map(lambda x: x in multi) & (poss.Tm == 'TOT') ]\n",
    "poss2 = poss[~poss.srID.map(lambda x: x in multi)]\n",
    "poss = pd.concat([poss1,poss2]).set_index('srID')\n",
    "\n",
    "df_nba = pd.merge(poss,adv,how=\"inner\", left_index=True, right_index=True)\n",
    "df_nba = df_nba.dropna(1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = {}\n",
    "for p in base['players']:\n",
    "    if 'srID' not in p:\n",
    "        continue\n",
    "    heights[p['srID']] = p['hgt']\n",
    "df_nba['height'] = pd.Series(heights)\n",
    "df_nba = df_nba.dropna()\n",
    "df_nba.columns = [_.replace('%','p') for _ in df_nba.columns]\n",
    "df_nba['height'] = np.clip((df_nba.height-66)*3.70,0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATE_SCALES = ['FG%','TS%','3P%','FT%','3PAr','2P%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_vectors = []\n",
    "player_scales = []\n",
    "player_heights = []\n",
    "player_names = []\n",
    "for idx,row in df_nba.iterrows():\n",
    "    d = dict(row)\n",
    "    \n",
    "    d['Hgt'] = row['height']\n",
    "    d['Age']= row['Age_x']\n",
    "\n",
    "    d['DRE'] = -8.4+ 0.8*d['PTS'] -0.7*(d['FGA']-d['3PA']) -0.6*d['3PA'] - 0.2*d['FT'] + 0.1*d['ORB'] + 0.4*d['DRB'] + 0.5*d['AST'] + 1.7*d['STL'] + 0.8*d['BLK'] - 1.4*d['TOV'] - 0.1*d['PF']\n",
    "    d['3PtP'] = (2/(1+np.exp(-d['3PA']))-1)*d['3Pp']\n",
    "    d['Creation'] = d['AST']*0.1843+(d['PTS']+d['TOV'])*0.0969-2.3021*d['3PtP']+0.0582*(d['AST']*(d['PTS']+d['TOV'])*d['3PtP'] )-1.1942\n",
    "    d['Load'] = (d['AST']-(0.38*d['Creation'])*0.75)+d['FGA']+d['FTA']*0.44+d['Creation']+d['TOV']\n",
    "    d['cTOV'] = d['TOV']/d['Load']\n",
    "    #d['DPM'] = d['BLK']*0.802+d['DRB']*0.42-4.7-0.07551*d['PF']+1.597019*d['STL']-0.26385*d['TOV']\n",
    "    #d['OPM'] = -8.57647+0.6111*d['PTS']-0.33918*(0.44*d['FTA']+d['FGA'])+0.440814*d['FTA']+0.379745*d['3PA']+0.634044*d['AST']+0.77827*d['ORB']-1.08855*d['TOV']+0.26262*d['STL']\n",
    "    #d['BPM'] = d['OPM']+d['DPM']\n",
    "\n",
    "    MPo = np.maximum(1,np.nan_to_num(d['MP_x']))\n",
    "    MP = MPo\n",
    "    for statn in adv_stat_list:\n",
    "        d[statn+'p36_G72'] = 72*36*float(d[statn])/MPo#72*36*d[statn]/MPo\n",
    "    for s in RATE_SCALES:\n",
    "        d[s.replace('%','p')] *= 100\n",
    "    \n",
    "    d['MP'] = row['MP_x']/row['G_x']\n",
    "    d['Blk'] = d['BLK']\n",
    "\n",
    "    player_vectors.append([d[stat.replace('p36','').replace('%','p') if 'G72' not in stat else stat] for stat in X.columns])\n",
    "    player_scales.append(MP)\n",
    "    player_heights.append(d['Hgt'])\n",
    "    player_names.append(idx)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(player_vectors,columns=X.columns)#.iloc[player_names.index('Collin Sexton')]\n",
    "#player_scales[93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = np.nan_to_num(np.array(player_vectors))\n",
    "Xn = np.nan_to_num(Xn)\n",
    "first_n = Xn.shape[0]\n",
    "#Xn.shape,Xn_s.shape,prescale_X.shape,fexp.n_input_features_,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array(player_scales)\n",
    "print(c.max())\n",
    "scaling = (c.max()/3028) * 256 # adjust for era\n",
    "c = np.array(player_scales).reshape((-1,1))\n",
    "c = np.tanh(c/scaling) # basically 1 by 512 MP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,250),np.tanh(np.linspace(0,250) * (256/3028)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-100]  + list(range(30,85)) + [200]\n",
    "base_hist = np.histogram((y*ovr_v).sum(1),bins,density=True)[0] + 1e-9\n",
    "\n",
    "def just_a_thing(qrange):\n",
    "    #Xn = np.nan_to_num(np.array(player_vectors))\n",
    "    # tuned this to get roughly 8-12 players at 70 or above. Which seemed like normal for a league\n",
    "    scalerX2 = preprocessing.RobustScaler(quantile_range=tuple(qrange))\n",
    "\n",
    "    #scalerX2 = scalerX\n",
    "    Xn_s = fexp.transform(np.nan_to_num(Xn))\n",
    "    Xsub = Xn_s[:first_n]\n",
    "    Xsub = Xsub[(c.ravel()[:first_n] > 0.15)]\n",
    "\n",
    "    scalerX2.fit(Xsub)\n",
    "    Xn_fs =scalerX2.transform(Xn_s)\n",
    "\n",
    "\n",
    "    predict =clf.predict(Xn_fs) #  Xn_fs @ coef#\n",
    "    ratings = np.nan_to_num(scalery.inverse_transform(predict))\n",
    "    #ratings[:,0] = Xn[:,list(X.columns).index('Hgt')]\n",
    "    HGT_PRED = 0.35\n",
    "    #if 'Hgt' in list(X.columns):\n",
    "    #ratings[:,0] = HGT_PRED*ratings[:,0] + (1-HGT_PRED)* np.array(player_heights)\n",
    "    ratings[:,0] = HGT_PRED*np.array(player_heights) + (1-HGT_PRED)*np.maximum(ratings[:,0],np.array(player_heights))\n",
    "    # now we can sample directly from ratings\n",
    "\n",
    "    # if we want to scale players down based on minutes played to replacement level\n",
    "    if True:\n",
    "        ratings[:predict.shape[0]] = ratings[:predict.shape[0]]*c + (1-c)*np.repeat(np.array(replacement_player_mean_r).reshape((-1,1)),predict.shape[0],1).T\n",
    "    \n",
    "    est_hist = np.histogram((ratings*ovr_v).sum(1),bins,density=True)[0] + 1e-9\n",
    "    \n",
    "    kl1 = est_hist * np.log(est_hist/base_hist)\n",
    "    kl2 = base_hist * np.log(base_hist/est_hist)\n",
    "    return kl1.sum() + kl1.sum()\n",
    "qrange_init = [26.31838933, 69.76304586]\n",
    "just_a_thing(qrange_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "es = cma.CMAEvolutionStrategy(qrange_init,2)\n",
    "es.optimize(just_a_thing)\n",
    "qrange = es.best.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xn = np.nan_to_num(np.array(player_vectors))\n",
    "# tuned this to get roughly 8-12 players at 70 or above. Which seemed like normal for a league\n",
    "scalerX2 = preprocessing.RobustScaler(quantile_range=tuple(qrange))\n",
    "\n",
    "#scalerX2 = scalerX\n",
    "Xn_s = fexp.transform(np.nan_to_num(Xn))\n",
    "Xsub = Xn_s[:first_n]\n",
    "Xsub = Xsub[(c.ravel()[:first_n] > 0.15)]\n",
    "\n",
    "scalerX2.fit(Xsub)\n",
    "Xn_fs =scalerX2.transform(Xn_s)\n",
    "\n",
    "\n",
    "predict =clf.predict(Xn_fs) #  Xn_fs @ coef#\n",
    "ratings = np.nan_to_num(scalery.inverse_transform(predict))\n",
    "#ratings[:,0] = Xn[:,list(X.columns).index('Hgt')]\n",
    "HGT_PRED = 0.35\n",
    "#if 'Hgt' in list(X.columns):\n",
    "#ratings[:,0] = HGT_PRED*ratings[:,0] + (1-HGT_PRED)* np.array(player_heights)\n",
    "ratings[:,0] = HGT_PRED*np.array(player_heights) + (1-HGT_PRED)*np.maximum(ratings[:,0],np.array(player_heights))\n",
    "# now we can sample directly from ratings\n",
    "\n",
    "# if we want to scale players down based on minutes played to replacement level\n",
    "if True:\n",
    "    ratings[:predict.shape[0]] = ratings[:predict.shape[0]]*c + (1-c)*np.repeat(np.array(replacement_player_mean_r).reshape((-1,1)),predict.shape[0],1).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((ratings*ovr_v).sum(1),bins,alpha=0.5,density=True)\n",
    "plt.hist((y*ovr_v).sum(1),bins,alpha=0.5,density=True)\n",
    "plt.xlim(35,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn_fs[93,col_names.index('3PAp36^2')]\n",
    "#for k,v in zip(y.columns,ratings[93]):\n",
    "#    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for n,v in zip(X.columns,Xn_s[player_names.index('Draymond Green')]):\n",
    "#    print(n,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGT_PRED = 0.5\n",
    "player_heights = np.array(player_heights)\n",
    "\n",
    "def normalize(fro,to):\n",
    "    tm,ts = to.mean(),to.std()\n",
    "    fm,fs = fro.mean(),fro.std()\n",
    "    z = (fro-fm)/fs\n",
    "    return z*ts + tm\n",
    "nr = normalize(ratings[:,0],player_heights)\n",
    "tmp = np.clip(HGT_PRED*np.array(player_heights) + (1-HGT_PRED)*np.maximum(nr,player_heights),0,100)\n",
    "\n",
    "if True:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    _ = plt.hist(player_heights,15,alpha=0.8,density=True,label='NBA')\n",
    "    _ = plt.hist(np.clip(ratings[:,0],0,100),15,alpha=0.5,density=True,label='Model')\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,0.05)\n",
    "    plt.legend()\n",
    "    plt.subplot(1,3,2)\n",
    "    _ = plt.hist(player_heights,15,alpha=0.8,density=True,label='NBA')\n",
    "    plt.hist(tmp,15,alpha=0.5,density=True,label='Blended',color='#2ca02c')\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,0.05)\n",
    "    plt.legend()\n",
    "    plt.subplot(1,3,3)\n",
    "    _ = plt.hist(df['Hgt'],15,alpha=0.8,density=True,label='BBGM',color='#7f7f7f')\n",
    "    plt.hist(tmp,15,alpha=0.5,density=True,label='Blended',color='#2ca02c')\n",
    "    plt.xlim(0,100)\n",
    "    plt.ylim(0,0.05)\n",
    "    plt.legend()\n",
    "    plt.savefig('test.png',edgecolor='w',facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(player_heights,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ratings[:,0]\n",
    "#table_columns['per_minute']#,table_columns['advanced'].index('0-3')\n",
    "#for i,t in enumerate(player_stats[name]['advanced'][0]):\n",
    "#    print(i,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#player_vectors[player_names.index('Joel Embiid')][list(X.columns).index('OWSp36')],X.columns[list(X.columns).index('OWSp36')]\n",
    "#player_stats[2019]['Joel Embiid']['advanced'][0][12],player_stats[2019]['Joel Embiid']['per_game'][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plt.hist(Xn[:,list(X.columns).index('FTp36')],150,density=True,alpha=0.5,label='NBA')\n",
    "#_ = plt.hist(X['FTp36'],150,alpha=0.5,density=True,label='BBGM')\n",
    "#plt.legend()\n",
    "#plt.figure()\n",
    "_ = plt.hist(player_heights,15,density=True,alpha=0.5,label='NBA')\n",
    "_ = plt.hist(ratings[:,0],15,alpha=0.5,density=True,label='BBGM')\n",
    "plt.title('height distribution')\n",
    "plt.legend()\n",
    "plt.xlim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.mean(0)-Xn.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn.shape,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def load_roster(filename):\n",
    "    base = json.load(open(filename,'rb'))\n",
    "    players = base['players']\n",
    "    return players,base\n",
    "playersOG,base = load_roster('BBGM_ASG_2022_2022_preseason.json')\n",
    "abbrev_to_tid = {_['abbrev']:_['tid'] for _ in base['teams']}\n",
    "abbrev_to_tid['BRK'] = abbrev_to_tid['BKN']\n",
    "abbrev_to_tid['CHO'] = abbrev_to_tid['CHA']\n",
    "abbrev_to_tid['GSW'] = abbrev_to_tid['GS']\n",
    "abbrev_to_tid['NOP'] = abbrev_to_tid['NOL']\n",
    "abbrev_to_tid['NYK'] = abbrev_to_tid['NYC']\n",
    "abbrev_to_tid['SAS'] = abbrev_to_tid['SA']\n",
    "\n",
    "\n",
    "y_keys = [_.lower() for _ in y.columns]\n",
    "\n",
    "y_map = { 'hgt': 'hgt',\n",
    "   'stre': 'str',\n",
    "   'spd': 'spd',\n",
    "   'jmp': 'jmp',\n",
    "   'endu': 'end',\n",
    "   'ins': 'ins',\n",
    "   'dnk': 'dnk',\n",
    "   'ft': 'ft.1',\n",
    "   'fg': '2pt',\n",
    "   'tp': '3pt',\n",
    "   'diq': 'diq',\n",
    "   'oiq': 'oiq',\n",
    "   'drb': 'drb',\n",
    "   'pss': 'pss',\n",
    "   'reb': 'reb' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_ for _ in base['players'] if 'srID' in _ and _['srID'] == 'doncilu01']\n",
    "#base['players'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_lookup = {}\n",
    "r_min = {}\n",
    "for name,r,mp in zip(player_names,ratings,np.squeeze(c)):\n",
    "    r_vec = {k: r[y_keys.index(km)] for k,km in y_map.items()}\n",
    "    r_vec = {k: int(np.clip(v,0,100)) for k,v in r_vec.items()}\n",
    "    r_vec['season'] = GEN_YEAR\n",
    "    r_lookup[name] = r_vec\n",
    "    r_min[name] = mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_cols =['value','valueNoPot','valueFuzz','valueNoPotFuzz','fuzz']\n",
    "for i in range(len(base['players'])):\n",
    "    if 'srID' not in base['players'][i]:\n",
    "        continue\n",
    "    srID = base['players'][i]['srID']\n",
    "    if srID not in r_lookup:\n",
    "        continue\n",
    "    if r_min[srID] < 0.8:\n",
    "        continue\n",
    "    base['players'][i]['ratings'][-1] = r_lookup[srID]\n",
    "    for idx in range(len(base['players'][i]['ratings'])):\n",
    "        for thing in filt_cols:\n",
    "            rt = base['players'][i]['ratings'][idx]\n",
    "            if thing in rt:\n",
    "                del base['players'][i]['ratings'][idx][thing]\n",
    "    for thing in filt_cols:\n",
    "        if thing in base['players'][i]:\n",
    "            del base['players'][i][thing]\n",
    "    if srID == 'hardeja01':\n",
    "        print(base['players'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('auto_roster_{}.json'.format(GEN_YEAR),'wt') as fp:\n",
    "    json.dump(base,fp, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_lookup['hardeja01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
